{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onderzoeksvraag 3: Kun je op basis van bepaalde keywords in de beschrijving een voorspelling doen over hoe hoog de score van deze wijn is? (Supervised - Regression/ Datavisualisatie)\n",
    "We willen onderzoeken of je de score van de wijn kunt bepalen aan de hand van sommige keywords die gevonden zijn in de titels en de beschrijving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Prep\n",
    "Voor dat we kunnen beginnen moeten we onderdelen van de data aanpassen en rechtzetten.\n",
    "## 1.1 Imports\n",
    "Eerst beginnen we met een aantal setting en imports te doen, deze zijn allemaal netjes gegroepeerd.\n",
    "### Let op!\n",
    "\n",
    "Is dit de eerste keer dat dit bestand gedraaid wordt?<br>\n",
    "Uncomment dan `nltk.download()` in de cel hier onder en download dan alleen stopwords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download()\n",
    "# Only download stopwords!\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data cleaning\n",
    "Hier laden en schonen we de wijn data set op.\n",
    "\n",
    "Er staat een dictionary met alle foute waardes in alle colommen, eerst vervangen we die met nan.<br>\n",
    "Daarna verandere we de types naar het correcte type.<br>\n",
    "Dit doen we zodat we later in het programma nog kunnen beslissen wat we met de nan waardes doen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('redwine.csv', delimiter=';')\n",
    "chemColNames = ['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']\n",
    "\n",
    "colErrorPairs = {\n",
    "    'density'    : [' . '],\n",
    "    'citric acid': [' - ',' -   '],\n",
    "    'alcohol'    : ['100.333.333.333.333','11.066.666.666.666.600','956.666.666.666.667','923.333.333.333.333']}\n",
    "\n",
    "for colName in colErrorPairs:\n",
    "    for faultyString in colErrorPairs[colName]:\n",
    "        wine[colName] = wine[colName].replace(faultyString,np.nan)\n",
    "        \n",
    "wine['alcohol'] = wine['alcohol'].astype(float)\n",
    "wine['density'] = wine['density'].astype(float)\n",
    "wine['citric acid'] = wine['citric acid'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data wrangeling\n",
    "\n",
    "Hier proberen we de informatie te halen uit de data die we willen en in de vorm die we willen.<br>\n",
    "Het doel hier is alle text in `title` & `description` halen zodat we kunnen zoeken hoevaak sommige woorden genoemd worden.\n",
    "<br><br>\n",
    "Eerst selecteren we alleen `title` & `description`.<br>\n",
    "We proberen een grote lijst met losse woorden te maken om unieke woorden te kunnen tellen.<br>\n",
    "Per wijn splitten we de woorden naar losse strings, deze lijst maken we plat met `flatten` hier vervangen we alle delimiters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsPerWine = wine[['title','description']]\n",
    "allWordsSeperated = np.array(' '.join(wordsPerWine.to_numpy().flatten()).replace(',','').split(\" \"))\n",
    "allWordsSeperated = np.char.lower(allWordsSeperated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier kan je zien dat alle woorden los zijn gehaald.<br>\n",
    "Met een lengte van 118188 totale woorden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(allWordsSeperated[:20],'Amount of words',allWordsSeperated.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier initialiseren we het `wordFrame`, dit is een functie geworden omdat we later dingen gaan laten vallen en weer snel een nieuw frame willen.<br>\n",
    "<br>\n",
    "Belangrijk, eerst tellen we alle unieke woorden, hier komen 2 lijsten uit.\n",
    "`unique`: een lijst met alleen unieke woorden en `counts`: hoevaak dit woord getelt is.<br>\n",
    "Daarna wordt het aan een nieuw frame toegevoegd en de colommen en types goed gezet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.array(np.unique(allWordsSeperated, return_counts=True))\n",
    "def initWordFrame():\n",
    "    wordCount = np.array([np.array(unique), np.array(counts)])\n",
    "    wordFrame = pd.DataFrame(wordCount[0],wordCount[1]).reset_index()\n",
    "    wordFrame.columns = ['count','word']\n",
    "    wordFrame['count'] = wordFrame['count'].astype(int)\n",
    "    return wordFrame\n",
    "wordFrame = initWordFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier filteren we op woorden die minimaal `minCount` keer genoemd moeten zijn en ook niet in de stopwoorden lijst zit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total of unique seperated words: {wordFrame.shape[0]}')\n",
    "minCount = 400\n",
    "wordFrame.drop(wordFrame[ (wordFrame['word'].isin(stop_words)) | (wordFrame['count'] < minCount)].index , inplace=True)\n",
    "print(f'Total of unique seperated words with atleast a count of {minCount} & not a stopword: {wordFrame.shape[0]}')\n",
    "# wordFrame.sort_values(by=['count'], ascending=False).reset_index(drop=True)[:32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit is de verdeling van alle woorden die minimaal `400` keer genoemd zijn.<br>\n",
    "Onze redenatie hierachter is dat er sommige woorden misschien een groep aangeven of een gedacht/smaak en dat deze vaken zouden voorkomen.<br>\n",
    "Dit geeft ook een mooi max van `32` woorden aan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordFrame.boxplot(column='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier maken we een nieuwe colom aan in de initiele `wine` tabel waar het het aantal gevonden keywords in een wijn kunnen aangeven per wijn.<br>\n",
    "<br>\n",
    "Het aantal keywords in de `title` en de `description` worden geteld en toegevoegd aan `keyword_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['keyword_desc'] = wine['description'].str.count('|'.join(wordFrame['word'].to_list()))\n",
    "wine['keyword_title'] =  wine['title'].str.count('|'.join(wordFrame['word'].to_list()))\n",
    "wine[['points', 'keyword_desc', 'keyword_title', 'title','description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voordat we kunnen trainen met een lineair regressie model moeten we de data splitten dat doen we met een bestaande functie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['keyword_desc', 'keyword_title']\n",
    "\n",
    "# Feature waardes\n",
    "X = wine[features]\n",
    "X.fillna(X.mean(),inplace=True)\n",
    "\n",
    "# Target waardes\n",
    "y = wine['points']\n",
    "y.fillna(y.mean(),inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Model fitting\n",
    "Hier zullen we de gewonnen data toepassen op een lineair regressie model.\n",
    "## 2.1 Model fitten met waarde uit hypothese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "score = linreg.score(X_test,y_test)\n",
    "yPred = linreg.predict(X_test)\n",
    "meanError = np.sqrt(mean_squared_error(y_test,yPred))\n",
    "print(f'Score: {score}, Mean Error: {meanError}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Model testen met aandere waardes\n",
    "De lage score van het model hiervoor van `0.10xx` en de handmatig gekoze minimale woord waarde is aanleiding tot dit stuk code.<br>\n",
    "Hier proberen we meerder malen een nieuwe model te maken en het te trainen maar dan met aandere mimimale keywoord count.<br>\n",
    "We beginnen met een hoog minimum en we gaan geleidelijk minderen en zo voegen we woorde toe om het verschil te zien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxRange = 22\n",
    "minRange = 4\n",
    "maxNumberRanges = [x*x for x in reversed(range(minRange,maxRange))]\n",
    "\n",
    "# Target waardes\n",
    "y = wine['points']\n",
    "y.fillna(y.mean(),inplace=True)\n",
    "\n",
    "for minCount in maxNumberRanges:\n",
    "    \n",
    "    wordFrame = initWordFrame()\n",
    "    wordFrame.drop(wordFrame[ (wordFrame['word'].isin(stop_words)) | (wordFrame['count'] < minCount)].index , inplace=True)\n",
    "#     Veranderd niks aan de score\n",
    "#     wordFrame['count'] = (wordFrame['count'] - wordFrame['count'].mean())/wordFrame['count'].std(ddof=0)\n",
    "\n",
    "    print(f'Total of unique seperated words with atleast a count of {minCount} & not a stopword: {wordFrame.shape[0]}')\n",
    "    \n",
    "    wine['keyword_desc'] = wine['description'].str.count('|'.join(wordFrame['word'].to_list()))\n",
    "    wine['keyword_title'] =  wine['title'].str.count('|'.join(wordFrame['word'].to_list()))\n",
    "    \n",
    "    # Feature waardes\n",
    "    X = wine[features]\n",
    "    X.fillna(X.mean(),inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=6)\n",
    "    \n",
    "    linRegTrial = LinearRegression()\n",
    "    linRegTrial.fit(X_train, y_train)\n",
    "    score = linRegTrial.score(X_test,y_test)\n",
    "    yPred = linRegTrial.predict(X_test)\n",
    "    meanError = np.sqrt(mean_squared_error(y_test,yPred))\n",
    "    print(f'Score: {score}, Mean Error: {meanError}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "Even een herhaling van de onderzoeksvraag.<br>\n",
    "Kun je op basis van bepaalde keywords in de beschrijving een voorspelling doen over hoe hoog de score van deze wijn is?\n",
    "\n",
    "## Verloop\n",
    "Verloop van het onderzoek.\n",
    "\n",
    "Mijn verwachting is dat als je een betere definitie hebt van 'niche' woorden, woorden die wat speciaals betekenen zoals 'grand cru' dat je een hogere score kan behalen.<br>\n",
    "Wat er nog had kunnen gebeuren is kleinere ranges met woorden gebruiken.<br> \n",
    "Eerst wordt ge-fit met een kleine groep woorden `n=32` van `minimum=400`, n wordt hier steeds groter door de 'versoepeling' van het aantal hits van deze keywords.<br>\n",
    "Dit hadden we ook vanaf de andere kant kunnen benaderen, zo hadden de veel gebruikte woorden weggelaten kunnen worden en hadden er gemakkelijker slices <b><i>tussen</i></b> de aantallen genomen kunnen worden.\n",
    "\n",
    "## Conclusie\n",
    "\n",
    "De conclusie die ik hier uit trek is dat het zeker mogelijk is maar nu nog niet goed genoeg, je ziet dat er een relatie is tussen <b><i>welke</i></b> woorden er worden geteld en de score.<br>\n",
    "En dat met een beter systeem,(misschien punten waardes geven aan alle woorden) er een beter resultaat uit komt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit5cdb2531dd3545ea9b3fd1a8a995abfc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
